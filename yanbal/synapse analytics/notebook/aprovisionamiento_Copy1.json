{
	"name": "aprovisionamiento_Copy1",
	"properties": {
		"folder": {
			"name": "utils"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "kyndryl",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "f9a199b5-a38b-46de-b708-89dcb1cdd829"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/e4516ad2-d1ef-463b-817c-b2a88c0b12bd/resourceGroups/rg-kyndryl/providers/Microsoft.Synapse/workspaces/synwkyndryl/bigDataPools/kyndryl",
				"name": "kyndryl",
				"type": "Spark",
				"endpoint": "https://synwkyndryl.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/kyndryl",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"# se define parametros de la base de datos\r\n",
					"name_database = \"staging\"\r\n",
					"location_database = \"abfss://staging@stakyndryl.dfs.core.windows.net/database/staging/\"\r\n",
					"\r\n",
					"# se define parametros de la tabla\r\n",
					"name_table = \"SalesOrderHeader\"\r\n",
					"location_table = \"abfss://staging@stakyndryl.dfs.core.windows.net/SalesOrderHeader\"\r\n",
					"partition_table = \"auditDate\"\r\n",
					"schema_table = \"\"\"SalesOrderID string,\r\n",
					"RevisionNumber string,\r\n",
					"OrderDate string,\r\n",
					"DueDate string,\r\n",
					"ShipDate string,\r\n",
					"Status string,\r\n",
					"OnlineOrderFlag string,\r\n",
					"SalesOrderNumber string,\r\n",
					"PurchaseOrderNumber string,\r\n",
					"AccountNumber string,    \r\n",
					"CustomerID string,\r\n",
					"ShipToAddressID string,\r\n",
					"BillToAddressID string,\r\n",
					"ShipMethod string,     \r\n",
					"CreditCardApprovalCode string,\r\n",
					"SubTotal string,\r\n",
					"TaxAmt string,\r\n",
					"Freight string,\r\n",
					"TotalDue string,\r\n",
					"Comment string, \r\n",
					"rowguid string,\r\n",
					"ModifiedDate string,\r\n",
					"auditDate date\"\"\"\r\n",
					"\r\n",
					""
				],
				"execution_count": 37
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"# se crea database\r\n",
					"spark.sql(f\"create database if not exists {name_database} LOCATION '{location_database}'\")\r\n",
					"\r\n",
					"print(f\"Database {name_database} created successfully\")\r\n",
					""
				],
				"execution_count": 38
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# se crea tabla\r\n",
					"spark.sql(f\"\"\"create table if not exists {name_database}.{name_table} ({schema_table}) using delta location '{location_table}'  PARTITIONED BY({partition_table})\"\"\")\r\n",
					"\r\n",
					"print(f\"Table {name_database}.{name_table} created successfully\")"
				],
				"execution_count": 39
			}
		]
	}
}